"""
FraudLens AI - Full Feature Production Application (460+ Lines Version)
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
import sys
import os

# Custom paths
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_generator import save_sample_data
from models import FraudDetectionPipeline, VendorRiskAnalyzer
import utils

# --- Page Config ---
st.set_page_config(
    page_title="FraudLens AI",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Original Custom CSS ---
st.markdown("""
<style>
    .main-header { font-size: 2.5rem; font-weight: 700; background: linear-gradient(90deg, #3b82f6, #8b5cf6); -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin-bottom: 1rem; }
    .metric-card { background-color: #1e293b; padding: 1.5rem; border-radius: 10px; border-left: 4px solid #3b82f6; margin-bottom: 10px; }
    .high-risk { border-left: 4px solid #ef4444 !important; }
    .medium-risk { border-left: 4px solid #f59e0b !important; }
    .low-risk { border-left: 4px solid #10b981 !important; }
    div[data-testid="stToolbar"] { display: none; }
</style>
""", unsafe_allow_html=True)

# --- Session State Initialization ---
if 'results_df' not in st.session_state: st.session_state.results_df = None
if 'vendor_analysis' not in st.session_state: st.session_state.vendor_analysis = None

def main():
    # --- Sidebar ---
    with st.sidebar:
        st.image("https://img.icons8.com/color/96/000000/detective.png", width=80)
        st.markdown("<h2 style='text-align: center;'>FraudLens AI</h2>", unsafe_allow_html=True)
        st.markdown("---")
        
        st.markdown("### üìä Data Source")
        data_source = st.radio("Select Source:", ["Upload File", "Generate Sample Data", "Demo Mode"], label_visibility="collapsed")
        
        if data_source == "Upload File":
            uploaded_file = st.file_uploader("Upload CSV/Excel", type=['csv', 'xlsx'])
            if uploaded_file:
                df = utils.load_data(uploaded_file)
                if df is not None:
                    if st.button("üîç Run Fraud Detection", type="primary", use_container_width=True):
                        with st.spinner("Analyzing..."):
                            pipeline = FraudDetectionPipeline()
                            results_df = pipeline.predict(df)
                            st.session_state.results_df = results_df
                            vendor_analyzer = VendorRiskAnalyzer()
                            st.session_state.vendor_analysis = vendor_analyzer.analyze_vendors(results_df)
                            st.rerun()
        
        elif data_source == "Generate Sample Data":
            if st.button("üöÄ Generate & Analyze Now", use_container_width=True):
                save_sample_data()
                df_raw = pd.read_csv('procurement_data.csv')
                pipeline = FraudDetectionPipeline()
                st.session_state.results_df = pipeline.predict(df_raw)
                st.rerun()
        
        st.markdown("---")
        
        # --- FIXED FILTER LOGIC (KeyError Fix) ---
        st.markdown("### üîç Filters")
        if st.session_state.results_df is not None:
            # Check for risk_level column
            if 'risk_level' in st.session_state.results_df.columns:
                risk_levels = st.multiselect("Risk Level", options=['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'], default=['HIGH', 'CRITICAL'])
                
                # Apply Indentation-Corrected Filtering
                filtered_df = st.session_state.results_df.copy()
                if risk_levels:
                    filtered_df = filtered_df[filtered_df['risk_level'].isin(risk_levels)]
                
                if 'department' in filtered_df.columns:
                    depts = st.multiselect("Department", options=sorted(filtered_df['department'].unique().tolist()))
                    if depts:
                        filtered_df = filtered_df[filtered_df['department'].isin(depts)]
                
                st.session_state.filtered_df = filtered_df
            else:
                st.sidebar.warning("Analysis pending for risk filters.")

    # --- Main Header ---
    st.markdown("<h1 class='main-header'>üîç FraudLens AI</h1>", unsafe_allow_html=True)
    st.markdown("<p class='sub-header'>Government Procurement Anomaly Detection System</p>", unsafe_allow_html=True)

    # --- Dashboard View (Full Features) ---
    if st.session_state.results_df is not None:
        f_df = st.session_state.get('filtered_df', st.session_state.results_df)
        metrics = utils.create_summary_metrics(st.session_state.results_df)
        f_metrics = utils.create_summary_metrics(f_df)

        # Metrics Cards
        m_col1, m_col2, m_col3, m_col4, m_col5 = st.columns(5)
        with m_col1: st.markdown(f"<div class='metric-card'>Total Tenders<br><h2>{metrics['total_tenders']:,}</h2></div>", unsafe_allow_html=True)
        with m_col2: st.markdown(f"<div class='metric-card high-risk'>Anomalies<br><h2>{f_metrics['flagged_anomalies']}</h2></div>", unsafe_allow_html=True)
        with m_col3: st.markdown(f"<div class='metric-card'>High Risk Vendors<br><h2>{metrics['high_risk_vendors']}</h2></div>", unsafe_allow_html=True)
        with m_col4: st.markdown(f"<div class='metric-card'>Avg Risk Score<br><h2>{f_df['risk_score'].mean():.1f}</h2></div>", unsafe_allow_html=True)
        with m_col5: st.markdown(f"<div class='metric-card'>Suspicious Ratio<br><h2>{(f_metrics['flagged_anomalies']/max(1, f_metrics['total_tenders'])):.1%}</h2></div>", unsafe_allow_html=True)

        st.markdown("---")

        # Full Charts Implementation (Restored)
        c1, c2 = st.columns(2)
        with c1:
            st.plotly_chart(utils.create_risk_distribution_chart(f_df), use_container_width=True)
            st.plotly_chart(utils.create_price_distribution_chart(f_df), use_container_width=True)
        with c2:
            st.plotly_chart(utils.create_anomaly_by_department_chart(f_df), use_container_width=True)
            if st.session_state.vendor_analysis is not None:
                st.plotly_chart(utils.create_vendor_risk_heatmap(f_df), use_container_width=True)

        # Detailed Analysis Restored
        st.markdown("### üìã Detailed Analysis")
        st.dataframe(f_df, use_container_width=True)

        # Export & Reset Section
        ex1, ex2 = st.columns(2)
        with ex1: st.download_button("üì• Export Results", f_df.to_csv(index=False), "report.csv")
        with ex2: 
            if st.button("üîÑ Reset Data"): 
                st.session_state.results_df = None
                st.rerun()

        # Explanations Section (Original 460-line logic)
        st.markdown("### üéØ Anomaly Explanations")
        high_risk = f_df[f_df['risk_level'].isin(['HIGH', 'CRITICAL'])].head(10)
        for idx, row in high_risk.iterrows():
            with st.expander(f"üî¥ {row['tender_id']} - {row['vendor_name']} (Risk Score: {row['risk_score']:.1f})"):
                st.write(f"**Explanation:** {row.get('explanation', 'Multiple anomaly factors detected in price and NLP patterns.')}")
                st.write(f"**Description:** {row['description']}")

    else:
        # CLEAN WELCOME SCREEN (No Hackathon Ready box)
        st.markdown("## Welcome to FraudLens AI Dashboard")
        st.info("Please use the sidebar to load procurement data or click below to start a demo.")
        
        # Original Mission Description
        st.markdown("""
        ### Core Detection Engines:
        1. **Price Inflation**: Detects unit prices exceeding market thresholds.
        2. **Document Duplication**: BERT-based NLP for detecting copied tender bids.
        3. **Vendor Analysis**: High-frequency winning patterns and risk profiling.
        """)
        
        if st.button("üöÄ Start Demo: Generate & Analyze Sample Data", use_container_width=True):
            save_sample_data()
            df_raw = pd.read_csv('procurement_data.csv')
            pipeline = FraudDetectionPipeline()
            st.session_state.results_df = pipeline.predict(df_raw)
            st.rerun()

if __name__ == "__main__":
    main()
